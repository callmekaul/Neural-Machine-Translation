{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tune(GU-HI)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLfx2cobDIYN"
      },
      "source": [
        "Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGoqKPZ4YJDe",
        "outputId": "4dcd784b-a7fe-4c99-f372-557ca9939194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "!pip install inltk\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import inltk\n",
        "from inltk.inltk import tokenize\n",
        "from inltk.inltk import setup\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: inltk in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from inltk) (20.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from inltk) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from inltk) (1.0.5)\n",
            "Requirement already satisfied: fastai==1.0.57 in /usr/local/lib/python3.6/dist-packages (from inltk) (1.0.57)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from inltk) (0.2.3)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from inltk) (2.2.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from inltk) (7.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from inltk) (4.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from inltk) (1.4.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from inltk) (0.7)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from inltk) (7.352.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from inltk) (0.1.91)\n",
            "Requirement already satisfied: aiohttp>=3.5.4 in /usr/local/lib/python3.6/dist-packages (from inltk) (3.6.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from inltk) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from inltk) (3.2.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from inltk) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from inltk) (1.18.5)\n",
            "Requirement already satisfied: async-timeout>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from inltk) (3.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from inltk) (2.23.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from inltk) (2.7.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->inltk) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->inltk) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->inltk) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->inltk) (2.8.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.57->inltk) (0.6.1+cu101)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.57->inltk) (1.5.1+cu101)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (49.1.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (0.7.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->inltk) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (3.7.4.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (19.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (1.4.2)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (1.1.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (3.0.4)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp>=3.5.4->inltk) (4.7.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->inltk) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->inltk) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->inltk) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->inltk) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->inltk) (2020.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.57->inltk) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (3.1.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2UbHQwXYTgt"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 200\n",
        "\n",
        "#initialize Lang Class\n",
        "class Lang:\n",
        "   def __init__(self):\n",
        "       #initialize containers to hold the words and corresponding index\n",
        "       self.word2index = {}\n",
        "       self.word2count = {}\n",
        "       self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "       self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "#split a sentence into words and add it to the container\n",
        "   def addSentence(self, sentence):\n",
        "       for word in sentence.split(' '):\n",
        "           self.addWord(word)\n",
        "\n",
        "#If the word is not in the container, the word will be added to it, \n",
        "#else, update the word counter\n",
        "   def addWord(self, word):\n",
        "       if word not in self.word2index:\n",
        "           self.word2index[word] = self.n_words\n",
        "           self.word2count[word] = 1\n",
        "           self.index2word[self.n_words] = word\n",
        "           self.n_words += 1\n",
        "       else:\n",
        "           self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJQo1m3cYa27"
      },
      "source": [
        "def process_data():\n",
        "\n",
        "  sf = open('/content/drive/My Drive/data/bible-uedin.gu-hi.gu' , \"r\")\n",
        "  tf = open('/content/drive/My Drive/data/bible-uedin.gu-hi.hi' , \"r\")\n",
        "\n",
        "  source = Lang()\n",
        "  target = Lang()\n",
        "  pairs = []\n",
        "  count = 0\n",
        "  count2 = 0\n",
        "  for sent in sf:\n",
        "    sent = sent.strip()\n",
        "    source.addSentence(sent)\n",
        "    pairs.append(sent)\n",
        "    count = count+1\n",
        "\n",
        "  # print(count)\n",
        "\n",
        "  for sent in tf:\n",
        "    sent = sent.strip()\n",
        "    target.addSentence(sent.strip())\n",
        "    pairs.append(sent)\n",
        "    count2 = count2 + 1\n",
        "\n",
        "  # print(count2)\n",
        "\n",
        "  pairs_new = []\n",
        "\n",
        "  for i in range(count):\n",
        "    full = [pairs[i],pairs[i+count]]\n",
        "    pairs_new.append(full)\n",
        "\n",
        "\n",
        "\n",
        "  return source, target, pairs_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92bJScQFZ3Kz"
      },
      "source": [
        "# source, target, pairs = process_data()   JUST A CHECK TO SEE IF THE SIZE OF BOTH DATASET IS SAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRftbm5OC9Mp"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsBdBN2bxdbC"
      },
      "source": [
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gUpG5q-DDop"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOZOdZTjdAWa"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PYQnQWvE0w5"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xdfq9OdXqG"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tFsKzhQda3T"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBjkaSjjdgDg"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        # plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "    #     if iter % plot_every == 0:\n",
        "    #         plot_loss_avg = plot_loss_total / plot_every\n",
        "    #         plot_losses.append(plot_loss_avg)\n",
        "    #         plot_loss_total = 0\n",
        "\n",
        "    # showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAP-AQedj8D"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(val_pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjNDMkSjdx42",
        "outputId": "31968247-8ff0-4f93-8949-c6c2ca07d570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_lang, output_lang, pairs = process_data()\n",
        "pairs = filterPairs(pairs)\n",
        "\n",
        "print(random.choice(pairs))\n",
        "\n",
        "print(len(pairs))\n",
        "x = len(pairs)\n",
        "\n",
        "trainSplit = int(x*0.7)\n",
        "valSplit = trainSplit + int(x*0.2)\n",
        "\n",
        "train_pairs = pairs[:trainSplit]\n",
        "val_pairs = pairs[trainSplit:valSplit]\n",
        "test_pairs = pairs[valSplit:]\n",
        "\n",
        "print(len(train_pairs))\n",
        "print(len(val_pairs))\n",
        "print(len(test_pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['હું એમ કહેવા માગું છું કે આપણને જેમાં વિશ્વાસ છે તેના વડે આપણે એકબીજાને મદદ કરી શકીએ છીએ. તમારો વિશ્વાસ મને મદદ કરશે, અને મારો વિશ્વાસ તમને.', 'अर्थात् यह, कि मैं तुम्हारे बीच में होकर तुम्हारे साथ उस विश्वास के द्वारा जो मुझ में, और तुम में है, शान्ति पाऊं।']\n",
            "7793\n",
            "5455\n",
            "1558\n",
            "780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F5bEVeZzcXW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwctMktLdqQw",
        "outputId": "d6cc3c22-2e7e-47ef-99b4-a567462d65f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "hidden_size = 256\n",
        "\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 30000, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1m 10s (- 34m 13s) (1000 3%) 5.4916\n",
            "2m 21s (- 32m 55s) (2000 6%) 5.2903\n",
            "3m 31s (- 31m 39s) (3000 10%) 5.0700\n",
            "4m 42s (- 30m 37s) (4000 13%) 4.9414\n",
            "5m 51s (- 29m 19s) (5000 16%) 4.8366\n",
            "7m 1s (- 28m 7s) (6000 20%) 4.6920\n",
            "8m 12s (- 26m 57s) (7000 23%) 4.7857\n",
            "9m 21s (- 25m 44s) (8000 26%) 4.6174\n",
            "10m 30s (- 24m 30s) (9000 30%) 4.5850\n",
            "11m 42s (- 23m 24s) (10000 33%) 4.5443\n",
            "12m 51s (- 22m 11s) (11000 36%) 4.4270\n",
            "14m 1s (- 21m 2s) (12000 40%) 4.4888\n",
            "15m 11s (- 19m 52s) (13000 43%) 4.4767\n",
            "16m 23s (- 18m 44s) (14000 46%) 4.3887\n",
            "17m 34s (- 17m 34s) (15000 50%) 4.3615\n",
            "18m 43s (- 16m 22s) (16000 53%) 4.2870\n",
            "19m 52s (- 15m 12s) (17000 56%) 4.2356\n",
            "21m 3s (- 14m 2s) (18000 60%) 4.2229\n",
            "22m 16s (- 12m 53s) (19000 63%) 4.2571\n",
            "23m 27s (- 11m 43s) (20000 66%) 4.1513\n",
            "24m 39s (- 10m 34s) (21000 70%) 4.1898\n",
            "25m 51s (- 9m 24s) (22000 73%) 4.1383\n",
            "27m 2s (- 8m 13s) (23000 76%) 4.1374\n",
            "28m 13s (- 7m 3s) (24000 80%) 4.0587\n",
            "29m 26s (- 5m 53s) (25000 83%) 4.1271\n",
            "30m 37s (- 4m 42s) (26000 86%) 4.0090\n",
            "31m 48s (- 3m 32s) (27000 90%) 3.9986\n",
            "33m 1s (- 2m 21s) (28000 93%) 4.0226\n",
            "34m 13s (- 1m 10s) (29000 96%) 4.0494\n",
            "35m 23s (- 0m 0s) (30000 100%) 3.9930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLSoH_89d5Eg",
        "outputId": "034e11bc-5e69-4e98-f22e-18cdf525c689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> નિશ્ચિત રીતે, જે સેવા આત્માનું અનુગમન કરાવે છે તેનો મહિમા તો આનાથી પણ મહાન થશે.\n",
            "= तो आत्मा की वाचा और भी तेजोमय क्यों न होगी?\n",
            "< इसलिये यदि मैं तो से से से से क्योंकि तो का क्योंकि से परन्तु क्योंकि का यदि तो का <EOS>\n",
            "\n",
            "> હું પાઉલ, મારા સ્વહસ્તે આ પત્ર લખી રહ્યો છું અને તમને ક્ષેમકુશળ પાઠવી રહ્યો છુ, કારાગારમાં મને યાદ કરજો. દેવની કૃપા (દયા) તમારા પર થાઓ.\n",
            "= मुझ पौलुस का अपने हाथ से लिखा हुआ नमस्कार। मेरी जंजीरों को स्मरण रखना; तुम पर अनुग्रह होता रहे। आमीन।।\n",
            "< हे हे हे हे हे हे हे हे हे हे हे हे नाम हे भाइयो, की आत्मा की आत्मा की आत्मा से तुम्हें तुम्हें बातों की बातों की ओर से परमेश्वर की ओर से है। <EOS>\n",
            "\n",
            "> વળી દૂતો સંબંધી દેવ કહે છે કે: “દેવ પોતાના દૂતોને વાયુ જેવા બનાવે છે, અને દેવ તેના સેવકોને અગ્નિની જવાળા જેવા બનાવે છે.” ગીતશાસ્ત્ર 104:4\n",
            "= और स्वर्गदूतों के विषय में यह कहता है, कि वह अपने दूतों को पवन, और अपने सेवकों को धधकती आग बनाता है।\n",
            "< यह वही ने है, जिस ने प्रभु को परमेश्वर की ओर की ओर <EOS>\n",
            "\n",
            "> મારા વહાલા ભાઈઓ અને બહેનો! ધ્યાનથી સાંભળો, આ દુનિયાના ગરીબ લોકો વિશ્વાસમાં ધનવાન બને અને દેવે પોતાના પ્રેમ રાખનારાઓને જે રાજ્ય આપવાનું વચન આપ્યું છે તે પ્રાપ્ત કરે માટે દેવે તેઓને પસંદ કર્યા છે.\n",
            "= हे मेरे प्रिय भाइयों सुनो; क्या परमेश्वर ने इस जगत के कंगालों को नहीं चुना कि विश्वास में धर्मी, और उस राज्य के अधिकारी हों, जिस की प्रतिज्ञा उस ने उन से की है जो उस से प्रेम रखते हैं?\n",
            "< क्योंकि परमेश्वर ने ने में से परमेश्वर की की है, की को परमेश्वर की है। की की परमेश्वर की पर परमेश्वर की की की परमेश्वर की ओर परमेश्वर की है। <EOS>\n",
            "\n",
            "> દેવે જ અમને દેવ તરફથી તેના લોકોને પ્રાપ્ત થયેલા નવા કરારના સેવક બનવાને શક્તિમાન બનાવ્યા છે. આ નવો કરાર તે લેખિત નિયમ નથી તે આત્માનો છે. લેખિત નિયમ મૃત્યુ લાવે છે, પરંતુ આત્મા જીવન બક્ષે છે.\n",
            "= जिस ने हमें नई वाचा के सेवक होने के योग्य भी किया, शब्द के सेवक नहीं बरन आत्मा के; क्योंकि शब्द मारता है, पर आत्मा जिलाता है।\n",
            "< परन्तु ने ने का मन में से जो परमेश्वर का का वचन है। <EOS>\n",
            "\n",
            "> પરંતુ તમે, ભાઈઓ અને બહેનો, તમારે અંધકારમાં (પાપ) જીવન જીવવું ના જોઈએ. અને તે દિવસ ચોરની જેમ તમારા પર આવી પડે તો તમે આશ્ચર્ય પામશો નહિ.\n",
            "= पर हे भाइयों, तुम तो अन्धकार में नहीं हो, कि वह दिन तुम पर चोर की नाई आ पड़े।\n",
            "< इसलिये तुम जो कि वे कि परन्तु परन्तु जो हो, परन्तु कि परन्तु तुम कि तो परन्तु नहीं परन्तु <EOS>\n",
            "\n",
            "> હું ઈચ્છું છું કે જે લોકો તમારી કનડગત કરે છે તેઓ સુન્નતની સાથે ખમીરનો પણ સમાવેશ કરશે.\n",
            "= भला होता, कि जो तुम्हें डांवाडोल करते हैं, वे काट डाले जाते!\n",
            "< इसलिये मैं मैं से से से से से से परमेश्वर से से के परमेश्वर से के के के <EOS>\n",
            "\n",
            "> જેમ પવિત્રશાસ્ત્રોમાં લખ્યું છે, “જે વ્યક્તિ એ ઘણું ભેગું કર્યુ છે તેની પાસે ઘણુ વધારે ન હતું, અને જે વ્યક્તિએ ધણું ઓછું ભેગું કર્યુ હતું તેની પાસે ખૂબ ઓછુ ન હતું.” નિર્ગમન 16:18\n",
            "= जेसा लिखा है, कि जिस ने बहुत बटोरा उसका कुछ अधिक न निकला और जिस ने थोड़ा बटोरा उसका कुछ कम न निकला।।\n",
            "< हे भाइयो, जो पर ब्याह में हैं, और और वह <EOS>\n",
            "\n",
            "> ખ્રિસ્તમાં તમારા ભાઈઓ અને બહેનો માટે પરસ્પર પ્રેમ રાખવા અંગે તમને કઈ લખવાની અમારે જરુંર નથી. દેવે તમને એકબીજાને પ્રેમ કરવા માટે બોધ આપ્યો જ છે.\n",
            "= किन्तु भाईचारे की प्रीति के विषय में यह अवश्य नहीं, कि मैं तुम्हारे पास कुछ लिखूं; क्योंकि आपस में प्रेम रखना तुम ने आप ही परमेश्वर से सीखा है।\n",
            "< परन्तु यदि ये बातें ये बातें ये बातें ये बातें ये बातें ये बातें ये बातें ये बातें बातें न परन्तु परमेश्वर का प्रेम तो से प्रेम का प्रेम <EOS>\n",
            "\n",
            "> લોકો તમારામાં રસ દાખવે તે સારું છે, જો તેમનો હેતુ શુદ્ધ હોય તો. આ હમેશા સાચું છે. આ હું તમારી સાથ હોઉં કે તમારાથી દૂર હોઉં, સાચું છે.\n",
            "= पर यह भी अच्छा है, कि भली बात में हर समय मित्रा बनाने का यत्न किया जाए, न केवल उसी समय, कि जब मैं तुम्हारे साथ रहता हूं।\n",
            "< हे मैं हे कि कि कि कि कि कि में <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLvGEhf0j0C1"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "   def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "       super().__init__()\n",
        "      \n",
        "#initialize the encoder and decoder\n",
        "       self.encoder = encoder\n",
        "       self.decoder = decoder\n",
        "       self.device = device\n",
        "     \n",
        "   def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "\n",
        "       input_length = source.size(0) #get the input length (number of words in sentence)\n",
        "       batch_size = target.shape[1] \n",
        "       target_length = target.shape[0]\n",
        "       vocab_size = self.decoder.output_dim\n",
        "      \n",
        "#initialize a variable to hold the predicted outputs\n",
        "       outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "#encode every word in a sentence\n",
        "       for i in range(input_length):\n",
        "           encoder_output, encoder_hidden = self.encoder(source[i])\n",
        "\n",
        "#use the encoder’s hidden layer as the decoder hidden\n",
        "       decoder_hidden = encoder_hidden.to(device)\n",
        "  \n",
        "#add a token before the first predicted word\n",
        "       decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
        "\n",
        "#topk is used to get the top K value over a list\n",
        "#predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n",
        "\n",
        "       for t in range(target_length):   \n",
        "           decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "           outputs[t] = decoder_output\n",
        "           teacher_force = random.random() < teacher_forcing_ratio\n",
        "           topv, topi = decoder_output.topk(1)\n",
        "           input = (target[t] if teacher_force else topi)\n",
        "           if(teacher_force == False and input.item() == EOS_token):\n",
        "               break\n",
        "\n",
        "       return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piwtmuh7jDWh"
      },
      "source": [
        "model = Seq2Seq(encoder1, attn_decoder1, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3a93SLXj2gD",
        "outputId": "0024cb07-a1eb-47da-d012-72c809ec866c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for name, params in model.named_children():\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder\n",
            "decoder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5faGpUDKlZwZ"
      },
      "source": [
        "for param in model.parameters():    \n",
        "    param.requires_grad = False\n",
        "\n",
        "trained_encoder = list(model.children())[0]\n",
        "trained_decoder = list(model.children())[1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6vf0E0ScfsV",
        "outputId": "1011a054-89db-4ef3-d408-f9cb2a70e0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "encoder2 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder2 = trained_decoder\n",
        "\n",
        "trainIters(encoder2, attn_decoder2, 15000, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 58s (- 8m 45s) (1000 10%) 4.1548\n",
            "1m 56s (- 7m 45s) (2000 20%) 4.0170\n",
            "2m 54s (- 6m 48s) (3000 30%) 4.0338\n",
            "3m 53s (- 5m 50s) (4000 40%) 4.1045\n",
            "4m 52s (- 4m 52s) (5000 50%) 4.0859\n",
            "5m 51s (- 3m 54s) (6000 60%) 4.1602\n",
            "6m 52s (- 2m 56s) (7000 70%) 4.0910\n",
            "7m 50s (- 1m 57s) (8000 80%) 4.0793\n",
            "8m 50s (- 0m 58s) (9000 90%) 4.0041\n",
            "9m 50s (- 0m 0s) (10000 100%) 4.0565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul6xiMFA6YA6",
        "outputId": "7b71897e-b6da-49f0-e75f-2af7cd8e40bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "new_model = Seq2Seq(encoder2, attn_decoder2, device).to(device)\n",
        "\n",
        "for param in new_model.parameters():    \n",
        "    param.requires_grad = True\n",
        "\n",
        "trained_encoder = list(new_model.children())[0]\n",
        "trained_decoder = list(new_model.children())[1] \n",
        "\n",
        "trainIters(trained_encoder, trained_decoder, 15000, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1m 12s (- 4m 49s) (1000 20%) 3.9567\n",
            "2m 27s (- 3m 40s) (2000 40%) 4.0008\n",
            "3m 39s (- 2m 26s) (3000 60%) 4.0228\n",
            "4m 54s (- 1m 13s) (4000 80%) 4.0314\n",
            "6m 7s (- 0m 0s) (5000 100%) 3.9701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WCaEOcIuVmV"
      },
      "source": [
        "def BLEU_score(encoder, decoder, n = len(test_pairs)):\n",
        "  score = 0\n",
        "  for i in range(n):\n",
        "        pair = random.choice(test_pairs)\n",
        "        reference = [pair[1].split(' ')]\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        candidate = output_sentence.split(' ')\n",
        "        i_score = sentence_bleu(reference, candidate)\n",
        "        score = score + i_score\n",
        "  avg_score = score/n\n",
        "\n",
        "  return(avg_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGLhsOdu3tb9",
        "outputId": "48a2a442-31cb-4f6a-8288-48044c74d160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "base_score = BLEU_score(encoder1,attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lT4QRK84-kd",
        "outputId": "9c66281a-d9c1-4a4b-9251-e9174ff2972b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tuned_score = BLEU_score(trained_encoder,trained_decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imhX4a8RgcRF",
        "outputId": "d536e501-aca4-4b48-c76f-fc061321ce6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Number of Training Pairs : \", len(train_pairs))\n",
        "print(\"Number of Validation Pairs : \", len(val_pairs))\n",
        "print(\"Number of Test Pairs : \", len(test_pairs))\n",
        "print(\"Base Model Score : \", base_score*100)\n",
        "print(\"Tuned Model Score : \", tuned_score*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training Pairs :  5455\n",
            "Number of Validation Pairs :  1558\n",
            "Number of Test Pairs :  780\n",
            "Base Model Score :  33.13479092383127\n",
            "Tuned Model Score :  34.20715932266964\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}